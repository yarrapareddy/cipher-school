{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Simple Chatbot Using **Python**"
      ],
      "metadata": {
        "id": "Ie2UjCKzyZWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction to NLP and Chatbot Frameworks\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### Definition and Importance of NLP\n",
        "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. The ultimate goal of NLP is to enable computers to understand, interpret, and generate human languages in a way that is both meaningful and useful.\n",
        "\n",
        "**Applications of NLP:**\n",
        "- Sentiment Analysis\n",
        "- Language Translation\n",
        "- Chatbots and Virtual Assistants\n",
        "- Text Summarization\n",
        "- Speech Recognition"
      ],
      "metadata": {
        "id": "8MZmp7IXyu22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common NLP Tasks\n",
        "#### Tokenization\n",
        "Tokenization is the process of breaking text into individual words or tokens.\n",
        "\n",
        "#### Stemming and Lemmatization\n",
        "Stemming and lemmatization are processes of reducing words to their root forms.\n",
        "\n",
        "#### Stop Words Removal\n",
        "Stop words are common words that add little meaning to text and are often removed in preprocessing."
      ],
      "metadata": {
        "id": "zzgt8zk4yxEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"Natural Language Processing is fascinating.\"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7p1v8h2y1fn",
        "outputId": "a7124260-8c58-45a1-dd7b-e2dc377b250f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'is', 'fascinating', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "words = [\"running\", \"ran\", \"runs\"]\n",
        "stems = [stemmer.stem(word) for word in words]\n",
        "print(stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZQx7iv0yqRm",
        "outputId": "7738476e-e001-443b-814f-c85169bf5c24"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'ran', 'run']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = [\"running\", \"ran\", \"runs\"]\n",
        "lemmas = [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
        "print(lemmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DzQD7Ajy_Lz",
        "outputId": "30c3b44a-9b68-46bf-8456-63debb6645c5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'run', 'run']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_text = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(filtered_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtHXaMmGzCJi",
        "outputId": "812106da-c194-407c-c8ec-4bd1e3892445"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'fascinating', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overview of Popular NLP Libraries\n",
        "#### NLTK (Natural Language Toolkit)\n",
        "NLTK is a powerful library for various NLP tasks, including tokenization, stemming, lemmatization, and more.\n",
        "\n",
        "#### SpaCy\n",
        "SpaCy is an open-source software library for advanced NLP tasks, known for its speed and efficiency.\n",
        "\n",
        "#### TextBlob\n",
        "TextBlob is a simple library for processing textual data, providing easy-to-use APIs for common NLP tasks."
      ],
      "metadata": {
        "id": "LRswP3FHzLoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to Chatbot Frameworks\n",
        "#### ChatterBot\n",
        "ChatterBot is a Python library that makes it easy to generate automated responses to a user's input.\n",
        "\n",
        "#### Rasa\n",
        "Rasa is an open-source framework for building conversational AI, including chatbots and voice assistants."
      ],
      "metadata": {
        "id": "-rfOt7GtzSZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Designing and Training a Simple Chatbot\n",
        "\n",
        "### Preprocessing Text Data\n",
        "Before training a chatbot, we need to preprocess the text data by tokenizing the text, removing stop words, and applying stemming or lemmatization."
      ],
      "metadata": {
        "id": "hi5TVi9EzVi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/chatbot_dataset.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "nltk.download('punkt')\n",
        "data['Question'] = data['Question'].apply(lambda x: ' '.join(nltk.word_tokenize(x.lower())))\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6whGpJSzaVe",
        "outputId": "89e68677-778c-45c9-9e50-d86bdd0cc6c9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Question  \\\n",
            "0                   introduction to the course   \n",
            "1  overview of data science and its importance   \n",
            "2    introduction to the data science workflow   \n",
            "3         key skills and tools in data science   \n",
            "4          where can i find my course videos ?   \n",
            "\n",
            "                                              Answer  \n",
            "0  Welcome to the data science course. Here you w...  \n",
            "1  Data science is crucial for making informed de...  \n",
            "2  The data science workflow includes data collec...  \n",
            "3  Important skills include programming, statisti...  \n",
            "4  You can find all your course videos on the Cip...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorizing Text Data\n",
        "We convert the text data into numerical values using TF-IDF (Term Frequency-Inverse Document Frequency) vectorization."
      ],
      "metadata": {
        "id": "DupM-Neazr79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(data['Question'])\n",
        "print(X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B6RmTvGzoCg",
        "outputId": "1788c914-6b3b-41a6-ea25-6a1ae1de86e9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48, 112)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the Naive Bayes classifier to train the model on the vectorized text data.\n"
      ],
      "metadata": {
        "id": "46OWachpz04D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['Question'], data['Answer'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a model pipeline\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXJJLeBjz163",
        "outputId": "0fed3d70-2c60-4ad5-f307-a2f6ba04c35d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RNBFHeHbz9HN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing a Function to Get Chatbot Responses\n",
        "We write a function to process user input and return responses based on the trained model."
      ],
      "metadata": {
        "id": "ZjZyXO58z80w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get a response from the chatbot\n",
        "def get_response(question):\n",
        "    question = ' '.join(nltk.word_tokenize(question.lower()))\n",
        "    answer = model.predict([question])[0]\n",
        "    return answer\n",
        "\n",
        "# Testing the function\n",
        "print(get_response(\"What is NLP?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npoe8K6Cz9l5",
        "outputId": "fcaaf438-b458-45ad-a454-289a305586b2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seaborn is a Python visualization library based on Matplotlib that provides a high-level interface for drawing attractive statistical graphics. This is covered in the Introduction to Matplotlib and Seaborn module.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iKp8Tkzq0FIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basics of Dash and Plotly\n",
        "\n",
        "In this notebook, we will cover the basics of Dash and Plotly. We will explain the essential components used to create a simple web application."
      ],
      "metadata": {
        "id": "q-oZwhBd0EuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zi6UsJWL0JFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing the Dash App\n",
        "\n",
        "To start using Dash, you need to import the Dash module and create an instance of the Dash class. This instance will be your app."
      ],
      "metadata": {
        "id": "V_8e9KVs0I0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb8jRZCG0Pc5",
        "outputId": "c0cfdcea-89ae-4f42-f65c-fc3a5241af25"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dash in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash) (3.0.3)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (5.15.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (5.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash) (8.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash) (2.31.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash) (67.7.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<3.1->dash) (2.1.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash) (3.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dash) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dash\n",
        "\n",
        "# Initialize the Dash app\n",
        "app = dash.Dash(__name__)"
      ],
      "metadata": {
        "id": "pNKOQa8n0F-3"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CYYgai1s0ZAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Layout\n",
        "\n",
        "The layout of a Dash app is defined using Dash's HTML and core components. The layout describes what the app looks like."
      ],
      "metadata": {
        "id": "t8rO4i8V0Ytm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dash import dcc, html\n",
        "\n",
        "# Define the layout\n",
        "app.layout = html.Div([\n",
        "    html.H1(\"My Dash App\", style={'textAlign': 'center'}),\n",
        "    dcc.Input(id='input-box', type='text', value='Type something...'),\n",
        "    html.Button('Submit', id='button'),\n",
        "    html.Div(id='output-div')\n",
        "])"
      ],
      "metadata": {
        "id": "UcuKcYvA0Zgn"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callback to Update the Output\n",
        "\n",
        "Callbacks in Dash are used to update the app's layout interactively. A callback is a function that gets automatically called by Dash whenever the input components' values change."
      ],
      "metadata": {
        "id": "tVOonGQF0fXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dash.dependencies import Input, Output\n",
        "\n",
        "# Define callback to update output\n",
        "@app.callback(\n",
        "    Output('output-div', 'children'),\n",
        "    Input('button', 'n_clicks'),\n",
        "    [dash.dependencies.State('input-box', 'value')]\n",
        ")\n",
        "def update_output(n_clicks, value):\n",
        "    if n_clicks is not None:\n",
        "        return f'You have entered: {value}'\n",
        "    return ''\n"
      ],
      "metadata": {
        "id": "o1eILx430c7H"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the App\n",
        "\n",
        "To run the app, you need to call the `run_server` method on the app instance. This will start a web server that serves the app."
      ],
      "metadata": {
        "id": "jt2Rav0R0wGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    app.run_server(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "9UnosMst36Fn",
        "outputId": "ee633ad8-7575-4472-d2f3-fe87a3ce84c5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Adding a Text Area\n",
        "\n",
        "You can add a text area to your Dash app using the `dcc.Textarea` component. This component allows the user to input multiline text."
      ],
      "metadata": {
        "id": "WjyHWwUq03YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "app.layout = html.Div([\n",
        "    html.H1(\"Chatbot\", style={'textAlign': 'center'}),\n",
        "    dcc.Textarea(\n",
        "        id='user-input',\n",
        "        value='Type your question here...',\n",
        "        style={'width': '100%', 'height': 100}\n",
        "    ),\n",
        "    html.Button('Submit', id='submit-button', n_clicks=0),\n",
        "    html.Div(id='chatbot-output', style={'padding': '10px'})\n",
        "])"
      ],
      "metadata": {
        "id": "x-KtRm8X05qu"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Creating a Chatbot Response\n",
        "\n",
        "We can create a simple chatbot response by defining a callback function that takes user input and generates a response."
      ],
      "metadata": {
        "id": "Br9Wz3mr1AMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callback to update chatbot response\n",
        "@app.callback(\n",
        "    Output('chatbot-output', 'children'),\n",
        "    Input('submit-button', 'n_clicks'),\n",
        "    [dash.dependencies.State('user-input', 'value')]\n",
        ")\n",
        "def update_output(n_clicks, user_input):\n",
        "    if n_clicks > 0:\n",
        "        return html.Div([\n",
        "            html.P(f\"You: {user_input}\", style={'margin': '10px'}),\n",
        "            html.P(f\"Bot: I am training now, ask something else.\", style={'margin': '10px', 'backgroundColor': '#f0f0f0', 'padding': '10px', 'borderRadius': '5px'})\n",
        "        ])\n",
        "    return \"Ask me something!\"\n"
      ],
      "metadata": {
        "id": "hivaMMHn09Mw"
      },
      "execution_count": 56,
      "outputs": []
    }
  ]
}